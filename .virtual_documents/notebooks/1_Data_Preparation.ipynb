import pandas as pd


df = pd.read_csv("E:/HealthCompass/data/raw/insurance.csv")


df.head()


df.smoker.value_counts()


df.sex.value_counts()


df['sex'] = df['sex'].apply(lambda x:1 if x=='male' else 0)
df['smoker'] = df['smoker'].apply(lambda x:1 if x=='yes' else 0)


df = df.join(pd.get_dummies(df.region, dtype=int)).drop('region', axis=1)


df


import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot = True, cmap='coolwarm', vmin = -1, vmax = 1)


from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import root_mean_squared_error, mean_absolute_error
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline


X = df.drop('charges', axis=1)
Y = df['charges']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)


modelPoly = make_pipeline(
    StandardScaler(),
    PolynomialFeatures(degree=2, include_bias=False),
    LinearRegression()
)


modelPoly.fit(X_train, Y_train)


Y_pred = modelPoly.predict(X_test)


mae = mean_absolute_error(Y_test, Y_pred)
mae


rmse = root_mean_squared_error(Y_test, Y_pred)
rmse


model = RandomForestRegressor(n_jobs=-1)
model.fit(X_train, Y_train)


model.score(X_test, Y_test)


Y_pred = model.predict(X_test)
rmse = root_mean_squared_error(Y_test, Y_pred)


rmse


df.charges.std()


mae = mean_absolute_error(Y_pred, Y_test)


mae


import numpy as np
plt.scatter(Y_test, Y_pred)
plt.plot(np.linspace(0,max(Y_test)), np.linspace(0,max(Y_pred)), color = 'red')
plt.xlabel('Charges')
plt.ylabel('Prediction')
plt.title('Prediction vs Truth')


feature_importances = sorted(zip(model.feature_names_in_, model.feature_importances_), key = lambda x: x[1], reverse=True)
plt.figure(figsize=(10,6))
plt.bar([x[0] for x in feature_importances], [x[1] for x in feature_importances])
plt.title('Feature importances')


from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth' : [None, 2, 5],
    'min_samples_split' : [2,4,6,8],
    'min_samples_leaf': [1,2,4,6]
}

model = RandomForestRegressor(n_jobs =-1)

grid_search = GridSearchCV(model, param_grid = param_grid, cv=5)


grid_search.fit(X_train, Y_train)


grid_search.best_params_


model = grid_search.best_estimator_


model


model.score(X_test, Y_test)


Y_pred = model.predict(X_test)


rmse = root_mean_squared_error(Y_test, Y_pred)
rmse





plt.scatter(Y_test, Y_pred)
plt.plot(np.linspace(0,max(Y_test)), np.linspace(0,max(Y_pred)), color = 'red')
plt.xlabel('Charges')
plt.ylabel('Prediction')
plt.title('Prediction vs Truth')


import joblib


joblib.dump(model, 'decision_tree_model.pkl')



